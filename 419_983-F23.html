<html>

<head>
<title>CMPT 419/983 - Theoretical Foundations of Reinforcement Learning (Fall 2023)</title>
<meta name="description" content="
Course webpage for CMPT 419/983 taught by Sharan Vaswani in Fall 2023."> 
</head>

<font face="helvetica">

<h1>CMPT 419/983 - Theoretical Foundations of Reinforcement Learning (Fall 2023)</h1>

Lectures (beginning Sep 8): Friday (2.30 pm - 5.20 pm) (AQ 3150) 
<p> Instructor: <a href="mailto:svaswani@sfu.ca">Sharan Vaswani</a> <p>

<p> TA: <a href="mailto:michael_lu_3@sfu.ca">Michael Lu</a> <p>

<b>Course Objective</b>: Numerous applications in machine learning involve interacting with the world, collecting data, and reasoning about it, all with incomplete information. Reinforcement Learning (RL) is a general framework for interactive learning and has been used for applications in clinical trials, monitoring industrial plants, robotics, games such as Atari and Go, and computational marketing. This course introduces the foundational concepts in bandits and RL from a rigorous theoretical perspective. The course intends to give students experience in: (1) Proving theoretical guarantees for reinforcement learning algorithms (2) Mapping problems in practical applications (e.g. recommender systems, social networks) to the RL framework (3) Developing and analyzing new bandit and RL algorithms
<p>

<b>Prerequisites</b>: Probability, Linear Algebra, Multivariable Calculus, Undergraduate Machine Learning
<p>

<b>Textbook</b>: There is no required textbook. We will use the following resources: 
<UL> 
<LI> <a href= "http://incompleteideas.net/book/RLbook2020.pdf"> Reinforcement Learning: An Introduction. Sutton and Barto, 2020 [SB20] </a>
<LI> <a href = "https://tor-lattimore.com/downloads/book/book.pdf"> Bandit Algorithms. Lattimore and Szepesvari, 2020 [LS20] </a>
<LI> <a href = "https://github.com/martyput/MDP_book"> Introduction to Markov Decision Processes. Puterman, Chan, 2023 [PC23]</a>	
<LI> <a href = "https://rltheorybook.github.io/rltheorybook_AJKS.pdf"> Reinforcement Learning: Theory and Algorithms. Agarwal, Jiang, Kakade and Sun, 2022 [AJKS22] </a>	
</UL>

<b>Grading</b>: Assignments 48%, Project 50%, Participation 2%
<p>
<a href="https://piazza.com/sfu.ca/fall2023/cmpt419983">Piazza</a> for course-related questions and discussions. 
<p>

<h2>List of topics</h2>
<UL>
<LI> Basics: Concentration inequalities, (Online) Convex Optimization
<LI> Bandits: Multi-armed/Contextual bandits framework, Regret minimization, Epsilon-greedy, Upper-confidence Bound
<LI> Markov Decision Processes: Structural properties, Bellman equation, Linear programming view of MDPs
<LI> MDPs: Algorithms in the tabular setting: Policy Evaluation, Temporal Difference Learning, Value Iteration, Policy Iteration
<LI> MDPs: Algorithms with function approximation: Approximate policy iteration, Politex, Policy gradients 
<LI> MDPs: Sample-complexity of model-based learning of MDPs under a generative model
<LI> MDPS: Regret minimization in the online setting using UCRL, LSVI-UCB
<!-- <LI> Constrained MDPs: Primal-dual algorithms for planning -->
</UL>

<h2>Schedule</h2>

<table width="80%" border="3" cellpadding="2">
<tbody><tr align="left">
<th>Date</th>
<th>Topics</th>
<th>Slides</th>
<th>References</th>
<th>Homework</th>
</tr>

<tr align="left">

<td> Friday Sep 8 </td>
<td> Course logistics, Multi-armed Bandits, Explore-then-Commit
<td> <a href="419_983-F23/L1.pdf">[L1]</a> </td>
<td> Chapters 4, 5, 6 of [LS20], <a href="https://vaswanis.github.io/210-W23.html"> [Refresher on Probability] </a> </td>
<td> </td>
</tr>

<tr>
<td> Friday Sep 15 </td>
<td> UCB, Linear Bandits, LinUCB </td>
<td> <a href="419_983-F23/L2.pdf">[L2]</a> </td>
<td> Chapters 7, 19 of [LS20], <a href="https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/video_galleries/video-lectures/">[Refresher on Linear Algebra]</a> <a href="https://www.lkozma.net/inequalities_cheat_sheet/ineq.pdf">[List of inequalities]</a> </td>
<td> Assignment 1 released </td>
</tr> 

<tr>
<td> Friday Sep 22 </td>
<td> LinUCB, Markov Decision Processes </td>
<td> <a href="419_983-F23/L3.pdf">[L3]</a> </td>
<td> Chapter 20 of [LS20], Chapter 2, 5.1 - 5.2 of [PC23] </td>
<td> </td>
</tr> 

<tr>
<td> Friday Sep 29 </td>
<td> Bellman Operators, Fundamental Theorem, Value Iteration </td>
<td> <a href="419_983-F23/L4.pdf">[L4]</a> </td>
<td> Chapter 5.2-5.5 of [PC23], <a href="https://rltheory.github.io/lecture-notes/planning-in-mdps/lec2/">[Lecture 2, Csaba notes]</a> <a href="https://rltheory.github.io/lecture-notes/planning-in-mdps/lec3/">[Lecture 3, Csaba notes]</a> </td>
<td> </td>
</tr> 

<tr>
<td> Friday Oct 6 </td>
<td> Policy Iteration, Linear Programming and MDPs</td>
<td> <a href="419_983-F23/L5.pdf">[L5]</a> </td>
<td> <a href="https://rltheory.github.io/lecture-notes/planning-in-mdps/lec4/">[Lecture 4, Csaba notes]</a>, Chapter 5.6, 5.8 of [PC23] </td>
<td> Assignment 1 due, Assignment 2 released </td>
</tr>   

<tr>
<td> Friday Oct 13 </td>
<td> Monte-Carlo for Policy Evaluation, Temporal Difference Learning </td>
<td> <a href="419_983-F23/L6.pdf">[L6]</a> </td>
<td> Chapter 5,6 of [SB20] <a href="https://arxiv.org/abs/1806.02450">[A Finite Time Analysis of Temporal Difference Learning With Linear Function Approximation]</a></td>
<td> </td>
</tr>     

<tr>
<td> Friday Oct 20 </td>
<td> Approximate Policy Iteration </td>
<td> <a href="419_983-F23/L7.pdf">[L7]</a> </td>
<td> <a href="https://rltheory.github.io/lecture-notes/planning-in-mdps/lec8/">[Lecture 8, Csaba notes]</a> </td>
<td style="color:red"> Project Proposal due </td>
</tr>   

<tr>
<td> Friday Oct 27 </td>
<td> Politex, Mirror Descent </td>
<td> <a href="419_983-F23/L8.pdf">[L8]</a> </td>
<td> <a href="https://rltheory.github.io/lecture-notes/planning-in-mdps/lec13/">[Lecture 13, Csaba notes]</a> <a href="https://rltheory.github.io/lecture-notes/planning-in-mdps/lec14/">[Lecture 14, Csaba notes]</a>, Chapter 4 of <a href="https://arxiv.org/abs/1405.4980">[Convex Optimization: Algorithms and Complexity]</a> </td>
<td> Assignment 2 due, Assignment 3 released </td>
</tr>   

<tr>
<td> Friday Nov 3 </td>
<td> 
<td> </td>
<td> </td>
<td> </td>
</tr> 

<tr>
<td> Friday Nov 10 </td>
<td> 
<td> </td>
<td> </td>
<td> </td>
</tr> 

<tr>
<td> Friday Nov 17 </td>
<td> 
<td> </td>
<td> </td>
<td> Assignment 3 due, Assignment 4 released </td>
</tr> 

<tr>
<td> Friday Nov 24 </td>
<td> 
<td> </td>
<td> </td>
<td> </td>
</tr> 

<tr align="left"> 
<td> Friday Dec 1 </td>
<td colspan="100%" style="color:red"> Project Presentations </td>
</tr> 

<tr align="left">
<td> Friday Dec 8 </td>
<td colspan="100%"> Assignment 4 due </td>
</tr>

<tr align="left"> 
<td> Friday Dec 15 </td>
<td colspan="100%" style="color:red"> Final Project Report due </td>
</tr>

</table>

<br>
<b> Related Courses </b>
<UL>    
<LI> <a href="https://rltheory.github.io/">UAlberta</a>
<LI> <a href="https://amfarahmand.github.io/IntroRL/">UToronto</a>	
<LI> <a href="https://shamulent.github.io/CS_Stat184_Fall22.html">Harvard</a> 
<LI> <a href="https://wensun.github.io/CS6789_spring_2023.html">Cornell</a> 	
<LI> <a href="https://nanjiang.cs.illinois.edu/cs542/">UIUC</a> 	
<LI> <a href="https://www.ambujtewari.com/stats701-winter2021/">UMichigan</a> 		
</UL> 
<p>
<BR>
</font>
</html>
