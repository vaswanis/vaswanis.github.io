<html>

<head>
<title>CMPT 409/981 - Optimization for Machine Learning  (Fall 2022)</title>
<meta name="description" content="
Course webpage for CMPT 409/981 taught by Sharan Vaswani in Fall 2022."> 
</head>

<font face="helvetica">

<h1>CMPT 409/981 - Optimization for Machine Learning  (Fall 2022)</h1>

Lectures (beginning Sep 8): Monday (2.30 pm - 3.20 pm) (WMC 2200) and Thursday (2.30 pm - 4.20 pm) (AQ 5037).<p>
Instructor: <a href="mailto:svaswani@sfu.ca">Sharan Vaswani</a>
<BR>
Instructor office hours: Monday 4 pm - 5 pm (TASC-1 8221)
<p>

<!-- Teaching Assistant: <a href="mailto:zmirikha@sfu.ca">Zahra MiriKharaji</a> 
<BR>
<p>
 -->

<b>Course Objective</b>: This course introduces the foundational concepts of convex and non-convex optimization with applications to machine learning. It will give the students experience in 1. Proving theoretical guarantees for optimization algorithms, 2. Analyzing machine learning (ML) problems from an optimization perspective and 3. Developing and analyzing new optimization methods for ML applications.
<p>

<b>Prerequisites</b>: Linear Algebra, Multivariable Calculus, (Undergraduate) Machine Learning
<p>

<b>Textbook</b>: There is no required textbook. We will use the following resources: 
<UL> 
<LI> Lectures on Convex Optimization, Nesterov, 2018
<LI> <a href = "https://stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf"> Convex Optimization, Boyd and Vandenberghe, 2004 </a>
<LI> <a href = "https://arxiv.org/abs/1405.4980">Convex Optimization: Algorithms and Complexity, Bubeck, 2014</a>
<LI> Numerical Optimization, Nocedal and Wright, 2006 
<LI> First-order Methods in Optimization, Beck, 2017  
</UL>

<b>Grading</b>: Assignments 50%, Project 50%
<p>
<a href="https://piazza.com/sfu.ca/fall2022/cmpt409981">Piazza</a> for course-related questions.
<p>

<h2>List of topics</h2>
<UL>
<LI> Basics: Subdifferentials, Optimality conditions, Lipschitz continuity, Convexity
<LI> (Non)-Convex minimization: (Projected/Proximal) Gradient Descent, Nesterov/Polyak momentum, Mirror Descent, Newton/Quasi-Newton methods
<LI> (Non)-Convex minimization: Stochastic gradient descent (SGD), Variance reduction techniques, Adaptivity for SGD, Coordinate Descent
<LI> Applications to training ML models (logistic regression, kernel machines, neural networks)
<LI> Online optimization: Regret minimization, Follow the (regularized) leader, Adaptive gradient methods (AdaGrad, Adam)
<LI> Applications to Imitation learning, Reinforcement learning
<LI> Min-Max optimization: (Stochastic) Gradient Descent-Ascent, (Stochastic) Extragradient
<LI> Applications to GANs, Robust optimization, Multi-agent RL
</UL>

<h2>Schedule</h2>

<table width="80%" border="3" cellpadding="2">
<tbody><tr align="left">
<th>Date</th>
<th>Topics</th>
<th>Slides</th>
<th>References</th>
<th>Homework</th>
</tr>

<tr align="left">
<td> Thursday Sep 8</td>
<td> Course logistics, Lipschitz continuity, Smoothness
<td> <a href="409_981-F22/L1.pdf">[L1]</a> </td>
<td> <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">[Matrix Cookbook]</a>
<a href="https://www.lkozma.net/inequalities_cheat_sheet/ineq.pdf">[List of inequalities]</a> 
<a href="https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/video_galleries/video-lectures/">[Linear Algebra Recap]</a> 
</td>
<td> </td>
</tr>

<tr align="left">
<td> Monday Sep 12</td>
<td> Gradient descent convergence for smooth non-convex functions, Exact line-search
<td> <a href="409_981-F22/L2.pdf">[L2]</a> </td>
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Sep 15</td>
<td> Convergence of GD with Back-tracking Armijo Line-search, Convex sets/functions
<td> <a href="409_981-F22/L3.pdf">[L3]</a> </td>
<td> Nocedal and Wright (3.1, 3.2), Boyd (2, 3)
<td> </td> 
</tr>

<tr align="left">
<td> Monday Sep 19</td>
<td colspan="100%" style="color:blue"> Holiday </td>

</tr>

<tr align="left">
<td> Thursday Sep 22</td>
<td> Convergence of GD for smooth, convex and strongly-convex functions
<td> <a href="409_981-F22/L4.pdf">[L4]</a> </td>
<td> Bubeck (3.2, 3.4), <a href="https://www.cs.ubc.ca/~schmidtm/Courses/Notes/convex.pdf">[Convex Optimization Cheat Sheet]</a>  
<td> Assignment 1 released </td>
</tr>

<tr align="left">
<td> Monday Sep 26</td>
<td> 
<td> <a href="409_981-F22/L5.pdf">[L5]</a> </td>
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Sep 29</td>
<td colspan="100%" style="color:blue"> Holiday </td>

<tr align="left">
<td> Monday Oct 3</td>
<td> 
<td> 
<td> 
<td> Assignment 1 due </td>
</tr>

<tr align="left">
<td> Thursday Oct 6</td>
<td> 
<td> 
<td> 
<td> Assignment 2 released </td>
</tr>

<tr align="left">
<td> Monday Oct 10</td>
<td colspan="100%" style="color:blue"> Holiday </td>
</tr>

<tr align="left">
<td> Thursday Oct 13</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Oct 17</td>
<td> 
<td> 
<td> 
<td> Assignment 2 due </td>
</tr>

<tr align="left">
<td> Thursday Oct 20</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Oct 24</td>
<td> 
<td> 
<td> 
<td> Project Proposal due </td>
</tr>

<!--
<tr align="left">
<td> Thursday Oct 27</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Oct 31</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Nov 3</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Nov 7</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Nov 10</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Nov 14</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Nov 17</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Nov 21</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Nov 24</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Monday Nov 28</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>

<tr align="left">
<td> Thursday Dec 1</td>
<td colspan="100%" style="color:blue"> NeurIPS </td>
</tr>

<tr align="left">
<td> Monday Dec 5</td>
<td> 
<td> 
<td> 
<td> </td>
</tr>
-->
</table>

<br>
<b> Related Courses </b>
<UL>    
<LI> <a href="https://www.cs.ubc.ca/~schmidtm/Courses/5XX-S22/">UBC'22</a>
<LI> <a href="https://www.cs.ubc.ca/~schmidtm/Courses/5XX-S20/">UBC'20</a>	
<LI> <a href="https://optml.mit.edu/teach/6881/">MIT</a> 
<LI> <a href="https://www.youtube.com/playlist?list=PLXsmhnDvpjORzPelSDs0LSDrfJcqyLlZc">UT Austin</a> 	
<LI> <a href="http://www.seas.ucla.edu/~vandenbe/236C/">UCLA</a> 	
<LI> <a href="https://stanford.edu/~boyd/cvxbook/">Stanford</a> 		
</UL> 
<p>

<BR>
</font>
</html>
